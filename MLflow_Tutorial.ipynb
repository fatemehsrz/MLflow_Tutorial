{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca052d93-0842-4b2e-83fe-69edbdf8ba6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### installing the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d35ac5b-a00e-4df8-84af-82ec74ca33ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install xgboost    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a model via MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bb2b85-085b-4e9a-9ca4-e79686944a5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "def RRMSE(true, pred):\n",
    "\n",
    "    num = np.sum(np.square(true - pred))\n",
    "    den = np.sum(np.square(pred))\n",
    "    \n",
    "    squared_error = num/den\n",
    "    rrmse_loss = np.sqrt(squared_error)\n",
    "    \n",
    "    return rrmse_loss\n",
    "\n",
    "\n",
    "\n",
    "def model_register(data_collector, model_name):\n",
    "    \n",
    "    experiment_name=\"ML_Exp\"\n",
    "   \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "     \n",
    "    with mlflow.start_run(run_name= model_name):\n",
    "        \n",
    "        mlflow.autolog()\n",
    "        \n",
    "        tsp=TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        client = MlflowClient()\n",
    "        \n",
    "        X_train= data_collector['X_train']\n",
    "        y_train= data_collector['y_train']\n",
    "        \n",
    "        model = XGBRegressor()\n",
    "        \n",
    "        parameters = {'depth' : [8,10],'learning_rate' : [0.01, 0.1],'n_estimators': [100, 500, 1000]}\n",
    "        grid = GridSearchCV(estimator=model, param_grid = parameters, cv = tsp, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        model = XGBRegressor(**grid.best_params_)\n",
    "        \n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "        \n",
    "        autolog_run = mlflow.last_active_run()\n",
    "        mse=  mean_squared_error(y_train,train_pred)\n",
    "        rmse= math.sqrt(mse)\n",
    "        rrmse= RRMSE(y_train,train_pred)\n",
    "        mae= mean_absolute_error( y_train,train_pred)\n",
    "        r2= r2_score(y_train,train_pred)\n",
    "        \n",
    "        mape= mean_absolute_percentage_error(y_train,train_pred)\n",
    "        mlflow.log_metric('rmse', rmse)\n",
    "        mlflow.log_metric('rrmse', rrmse)\n",
    "        mlflow.log_metric('mape',mape)\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \n",
    "                         artifact_path=\"XGBoost_models/%s\"%model_name, \n",
    "                          registered_model_name=\"%s\"%model_name)\n",
    "        \n",
    "        vf = client.get_latest_versions(model_name, stages=[\"None\"])\n",
    "        print(\"The version of {} is {}\".format(model_name,vf[0].version))     \n",
    "        print('model %s has been registered '%model_name, '\\n')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3449a8a2-7198-47d7-9824-8a0a98ca7867",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_Xy(df):\n",
    "  \n",
    "    y=df.pop('target')\n",
    "\n",
    "    X=df\n",
    "  \n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the latest version of the model and the last update date (year-month-day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b68d3706-0bb2-4fe8-a649-f595e23ccb99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.entities.model_registry.model_version_status import ModelVersionStatus\n",
    "import mlflow\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def fetch_model_last_update(model_name):\n",
    "\n",
    "\n",
    "    client = MlflowClient() \n",
    "\n",
    "    vf= client.get_latest_versions(model_name, stages=[\"None\"])\n",
    "    \n",
    "    latest_vesrsion= vf[0].version\n",
    "\n",
    "    run_id= vf[0].run_id\n",
    "    run = mlflow.get_run(run_id)\n",
    "    run.data.tags['mlflow.log-model.history'] \n",
    "    \n",
    "    DT_split= DT.split('\":\"')[-3][:10]\n",
    "    REG_DATE=DT_split.split('-')\n",
    "\n",
    "    print('Model:',model_name, '  last training date:', REG_DATE[0]+'-'+REG_DATE[1]+'-'+REG_DATE[2])\n",
    "     \n",
    "    model_last_update= date(int(REG_DATE[0]), int(REG_DATE[1]), int(REG_DATE[2]))\n",
    "\n",
    "    return model_last_update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the latest version of the model and predict on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c9033f-1ab2-4f69-b434-eee37142f5ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from datetime import date, datetime\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import time, threading\n",
    "\n",
    "\n",
    "\n",
    "def test_prediction( df_test, model_name ):\n",
    "\n",
    "\n",
    "    client = MlflowClient() \n",
    "\n",
    "    vf= client.get_latest_versions(group, stages=[\"None\"])\n",
    "  \n",
    "    model_test = mlflow.pyfunc.load_model(model_uri=\"models:/%s/%s\"% (model_name, vf[0].version)) \n",
    "\n",
    "    \n",
    "    X_test, y_test= prepare_Xy(df_test)\n",
    "                      \n",
    "\n",
    "    y_pred= np.array(model_test.predict(X_test))\n",
    "\n",
    "    mape= mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    r2= r2_score( y_test, y_pred)\n",
    "\n",
    "    return mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96bec554-d058-4cca-90a5-15ee0d3b4790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "def model_exist(model_name):\n",
    "\n",
    "  client = MlflowClient() \n",
    "\n",
    "  try:\n",
    "      print('existence check ...')\n",
    "      client.get_latest_versions(odel_name, stages=[\"None\"])\n",
    "\n",
    "  except:\n",
    "       print(odel_name, \"***** Model does not exist ****** \", '\\n')\n",
    "\n",
    "       return False\n",
    "\n",
    "  return True\n",
    "\n",
    "\n",
    "\n",
    "def update_data():\n",
    "     %run ./make_data_ready\n",
    "     \n",
    "\n",
    "\n",
    "def fetch_new_data():\n",
    "\n",
    "  old_data= spark.read.options(header='True', inferSchema='True', delimiter=',').csv(\"/dbfs/mnt/data\")\n",
    "                                                                                    \n",
    "  print('old data has been loaded ...')\n",
    "\n",
    "  update_data()\n",
    "\n",
    "  updated_data= spark.read.options(header='True', inferSchema='True', delimiter=',').csv(\"/dbfs/mnt/data\")\n",
    "  updated_dataset= updated_data.toPandas()\n",
    "\n",
    "  print('updated data has been loaded  ...')\n",
    "\n",
    "\n",
    "  if not updated_dataset.equals(old_dataset):\n",
    "\n",
    "      new_records= pd.concat([updated_data, old_data]).drop_duplicates(keep=False)\n",
    "\n",
    "      print('new data records ready ...')\n",
    "\n",
    "      return new_records, updated_dataset  \n",
    "\n",
    "  else:\n",
    "      return   old_dataset, updated_dataset  \n",
    "\n",
    "\n",
    "\n",
    "def model_drift_detector( df, model_name):\n",
    "    \n",
    "\n",
    "    new_records, updated_dataset =fetch_new_data(df)\n",
    " \n",
    "\n",
    "    test_mape, test_r2= test_prediction(new_records, model_name)\n",
    "    \n",
    "\n",
    "    print('Test MAPE:', test_mape, '  Test R2:', test_r2)\n",
    "\n",
    "\n",
    "    if test_mape >0.3 or test_r2 <0.85: \n",
    "\n",
    "        print('Drift detected: model should be retrained...')\n",
    "\n",
    "        model_register (updated_dataset, model_name)\n",
    "\n",
    "    else:\n",
    "        \n",
    "         print('No drift detected ...', '\\n')\n",
    "\n",
    "        \n",
    "      \n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "model_drift_detector(df, model_name)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3c09a6b-95eb-42ba-8f05-ebe42f2ccbf0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "203ff69b-023e-4085-ae15-c3afe7f5ae8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53bfa39d-dc12-4ef0-a0eb-c98aecfda05f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DRIFT_NEW_DATA",
   "notebookOrigID": 415565459887491,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
